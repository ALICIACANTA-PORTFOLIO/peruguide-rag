# ğŸ‡µğŸ‡ª PeruGuide AI

> **Transforming 5,000+ pages of official Peru tourism guides into an intelligent conversational assistant**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![LangChain](https://img.shields.io/badge/LangChain-0.1+-orange.svg)](https://langchain.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Code Quality](https://img.shields.io/badge/Code%20Quality-A-brightgreen.svg)](https://github.com/yourusername/peruguide-rag)

---

## ğŸ“– Table of Contents

- [Overview](#-overview)
- [The Problem](#-the-problem)
- [The Solution](#-the-solution)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Tech Stack](#-tech-stack)
- [Getting Started](#-getting-started)
- [Development Roles](#-development-roles)
- [Evaluation & Metrics](#-evaluation--metrics)
- [Documentation](#-documentation)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Overview

**PeruGuide AI** is a **production-ready RAG (Retrieval-Augmented Generation) system** that transforms academic research into a professional portfolio project. Built following best practices from:

- ğŸ“š **LLM Engineer's Handbook** (Iusztin & Labonne)
- ğŸ“š **Hands-On Large Language Models** (Alammar & Grootendorst)
- ğŸ“š **Build a Large Language Model from Scratch** (Raschka)
- ğŸ“š **Storytelling with Data** (Nussbaumer Knaflic)
- + 5 more authoritative sources (2,959 pages analyzed)

### **Key Features**

âœ… **3-Pipeline Architecture** (Feature â†’ Training â†’ Inference)  
âœ… **RAGAS Evaluation Framework** (Faithfulness >0.85)  
âœ… **Production-Grade Code** (>75% test coverage)  
âœ… **CI/CD Pipeline** (GitHub Actions)  
âœ… **Docker Containerization** (Easy deployment)  
âœ… **Comprehensive Documentation** (MkDocs)  
âœ… **Observability** (Structured logging, metrics)

---

## ğŸ­ The Problem

Every year, **4+ million tourists** visit Peru. Each spends an average of **5-8 hours** researching online, navigating through:

- âŒ 30+ scattered PDF guides (5,000+ pages)
- âŒ Contradictory blog posts and forums
- âŒ Generic travel advice without local context
- âŒ No source verification or trustworthiness

**Result:** Information overload, frustration, and suboptimal trip planning.

---

## ğŸ’¡ The Solution

PeruGuide AI provides an **intelligent conversational interface** to official Peru tourism documentation with:

| Feature | Traditional Search | PeruGuide AI |
|---------|-------------------|--------------|
| **Time to Plan** | 5-8 hours | 15-20 minutes âœ… |
| **Source Verification** | Manual | Automatic âœ… |
| **Personalization** | Generic | Tailored âœ… |
| **Information Quality** | Mixed | Official Sources âœ… |
| **Language Support** | Limited | Multilingual âœ… |

### **Demo**

```bash
User: "Â¿QuÃ© lugares visitar en Cusco en 3 dÃ­as?"

PeruGuide AI:
"Para un itinerario de 3 dÃ­as en Cusco, te recomiendo:

DÃ­a 1: Cusco Centro HistÃ³rico
- Plaza de Armas y Catedral (2-3 horas)
- Qoricancha - Templo del Sol (1 hora)
- San Blas (barrio artesanal)

DÃ­a 2: Valle Sagrado
- Pisac (mercado y ruinas)
- Ollantaytambo (complejo arqueolÃ³gico)

DÃ­a 3: Machu Picchu
- Salida temprano (5-6 AM)
- Tour guiado (2-3 horas)
- Retorno a Cusco

ğŸ“„ Fuentes:
- CUSCO GPPV - ESPAÃ‘OL_WEB_2023.pdf (pÃ¡gs. 23, 42, 67)
- GuÃ­a PrÃ¡ctica Valle Sagrado.pdf (pÃ¡gs. 12-18)

ğŸ” Confianza: 0.89 (Alta)"
```

---

## ğŸ—ï¸ Architecture

### **3-Pipeline Design Pattern**

Following the **LLM Engineer's Handbook** (Chapter 1, p.13), the system is built with three independent pipelines:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FEATURE PIPELINE                            â”‚
â”‚  (Data Ingestion â†’ Processing â†’ Vector Store)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PDFs (30+) â†’ Load â†’ Clean â†’ Chunk â†’ Embed â†’ FAISS/Chroma     â”‚
â”‚                                                                 â”‚
â”‚  Key Components:                                                â”‚
â”‚  â€¢ PyPDFLoader: Extract text from official guides              â”‚
â”‚  â€¢ RecursiveCharacterTextSplitter: chunk_size=512, overlap=64  â”‚
â”‚  â€¢ Multilingual-MPNet: 768-dim embeddings                      â”‚
â”‚  â€¢ Vector Store: FAISS (dev) / Chroma (prod)                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRAINING PIPELINE                            â”‚
â”‚  (Fine-tuning - Optional for Advanced Levels)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â€¢ Instruction dataset creation                                 â”‚
â”‚  â€¢ LoRA fine-tuning (Mistral-7B)                               â”‚
â”‚  â€¢ Preference alignment (DPO)                                   â”‚
â”‚  â€¢ Model evaluation & benchmarking                              â”‚
â”‚                                                                 â”‚
â”‚  Status: Planned for Level 3 (Portfolio Showcase)              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INFERENCE PIPELINE                           â”‚
â”‚  (RAG Chain â†’ Generation â†’ Response)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Query â†’ Process â†’ Retrieve (top-5) â†’ Rerank â†’ Context         â”‚
â”‚      â†’ Prompt â†’ LLM (Mistral-7B) â†’ Post-process â†’ Response     â”‚
â”‚                                                                 â”‚
â”‚  Key Components:                                                â”‚
â”‚  â€¢ Dense Retriever: Cosine similarity, threshold=0.7           â”‚
â”‚  â€¢ Context Assembly: Max 4K tokens with metadata               â”‚
â”‚  â€¢ Mistral-7B-Instruct: temperature=0.3 (factual)             â”‚
â”‚  â€¢ Citation Formatter: Source attribution tracking             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **System Architecture Diagram**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User (Web UI)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTPS
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Backend (REST API)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Routers:                                       â”‚   â”‚
â”‚  â”‚  â€¢ /api/v1/query     â†’ RAG Chain               â”‚   â”‚
â”‚  â”‚  â€¢ /api/v1/feedback  â†’ User feedback           â”‚   â”‚
â”‚  â”‚  â€¢ /api/v1/health    â†’ Health checks           â”‚   â”‚
â”‚  â”‚  â€¢ /api/v1/metrics   â†’ Prometheus metrics      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vector Store    â”‚      â”‚   LLM Service    â”‚
â”‚  (Chroma/FAISS)  â”‚      â”‚  (Mistral-7B)    â”‚
â”‚                  â”‚      â”‚                  â”‚
â”‚  â€¢ 30+ PDFs      â”‚      â”‚  â€¢ Temperature   â”‚
â”‚  â€¢ 5K+ chunks    â”‚      â”‚    0.3           â”‚
â”‚  â€¢ Embeddings    â”‚      â”‚  â€¢ Max tokens    â”‚
â”‚    768-dim       â”‚      â”‚    512           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
peruguide-rag/
â”‚
â”œâ”€ ğŸ“‚ analisis/                          # InvestigaciÃ³n y anÃ¡lisis previo
â”‚  â”œâ”€ materials_analysis_comprehensive.json
â”‚  â”œâ”€ PLANTEAMIENTO_DEFINITIVO_CON_ANALISIS.md
â”‚  â””â”€ deep_analysis_books.py
â”‚
â”œâ”€ ğŸ“‚ src/                               # CÃ³digo fuente principal
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ config.py                          # Pydantic settings & environment vars
â”‚  â”‚
â”‚  â”œâ”€ ğŸ“‚ data_pipeline/                  # FEATURE PIPELINE
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ ğŸ“‚ loaders/                     # Carga de datos
â”‚  â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”‚  â”œâ”€ pdf_loader.py                # PyPDFLoader wrapper
â”‚  â”‚  â”‚  â””â”€ directory_loader.py          # Batch loading
â”‚  â”‚  â”œâ”€ ğŸ“‚ processors/                  # Procesamiento de texto
â”‚  â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”‚  â”œâ”€ cleaner.py                   # Text cleaning & normalization
â”‚  â”‚  â”‚  â””â”€ metadata_extractor.py        # Extract metadata (dept, category)
â”‚  â”‚  â””â”€ ğŸ“‚ chunkers/                    # Estrategias de chunking
â”‚  â”‚     â”œâ”€ __init__.py
â”‚  â”‚     â””â”€ recursive_splitter.py        # RecursiveCharacterTextSplitter
â”‚  â”‚
â”‚  â”œâ”€ ğŸ“‚ embedding_pipeline/             # GeneraciÃ³n de embeddings
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ ğŸ“‚ models/
â”‚  â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”‚  â””â”€ sentence_transformer.py      # HuggingFace embeddings
â”‚  â”‚  â””â”€ batch_processor.py              # Batch embedding generation
â”‚  â”‚
â”‚  â”œâ”€ ğŸ“‚ vector_store/                   # Almacenamiento vectorial
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ abstract_store.py               # Abstract base class
â”‚  â”‚  â”œâ”€ faiss_store.py                  # FAISS implementation
â”‚  â”‚  â””â”€ chroma_store.py                 # ChromaDB implementation
â”‚  â”‚
â”‚  â”œâ”€ ğŸ“‚ retrieval_pipeline/             # INFERENCE PIPELINE (Retrieval)
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ ğŸ“‚ retrievers/
â”‚  â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”‚  â”œâ”€ dense_retriever.py           # Vector similarity search
â”‚  â”‚  â”‚  â””â”€ hybrid_retriever.py          # Dense + sparse (optional)
â”‚  â”‚  â””â”€ ğŸ“‚ rerankers/
â”‚  â”‚     â”œâ”€ __init__.py
â”‚  â”‚     â””â”€ cross_encoder.py             # Cross-encoder reranking
â”‚  â”‚
â”‚  â”œâ”€ ğŸ“‚ inference_pipeline/             # INFERENCE PIPELINE (Generation)
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ ğŸ“‚ llm/
â”‚  â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”‚  â”œâ”€ mistral_client.py            # Mistral-7B client
â”‚  â”‚  â”‚  â””â”€ prompt_templates.py          # System & user prompts
â”‚  â”‚  â”œâ”€ ğŸ“‚ chains/
â”‚  â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”‚  â””â”€ rag_chain.py                 # LangChain RAG orchestration
â”‚  â”‚  â””â”€ ğŸ“‚ postprocessing/
â”‚  â”‚     â”œâ”€ __init__.py
â”‚  â”‚     â”œâ”€ citation_formatter.py        # Format source citations
â”‚  â”‚     â””â”€ confidence_scorer.py         # Response confidence scoring
â”‚  â”‚
â”‚  â”œâ”€ ğŸ“‚ evaluation/                     # EvaluaciÃ³n con RAGAS
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ ragas_evaluator.py              # RAGAS metrics implementation
â”‚  â”‚  â”œâ”€ test_dataset.json               # Curated test Q&A pairs
â”‚  â”‚  â””â”€ metrics_logger.py               # Log evaluation results
â”‚  â”‚
â”‚  â””â”€ ğŸ“‚ utils/                          # Utilidades comunes
â”‚     â”œâ”€ __init__.py
â”‚     â”œâ”€ logger.py                       # Structured logging (structlog)
â”‚     â””â”€ monitoring.py                   # Metrics collection (Prometheus)
â”‚
â”œâ”€ ğŸ“‚ api/                               # FastAPI REST API
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ main.py                            # FastAPI app initialization
â”‚  â”œâ”€ ğŸ“‚ routers/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ query.py                        # /query endpoint (RAG)
â”‚  â”‚  â”œâ”€ feedback.py                     # /feedback endpoint
â”‚  â”‚  â””â”€ admin.py                        # /admin endpoints (health, metrics)
â”‚  â”œâ”€ ğŸ“‚ models/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â””â”€ schemas.py                      # Pydantic request/response models
â”‚  â””â”€ ğŸ“‚ middleware/
â”‚     â”œâ”€ __init__.py
â”‚     â”œâ”€ auth.py                         # Authentication (optional)
â”‚     â””â”€ rate_limit.py                   # Rate limiting
â”‚
â”œâ”€ ğŸ“‚ app/                               # Streamlit UI
â”‚  â”œâ”€ Home.py                            # Main Streamlit app
â”‚  â””â”€ ğŸ“‚ pages/
â”‚     â”œâ”€ Chat.py                         # Chat interface
â”‚     â”œâ”€ Sources.py                      # Browse sources
â”‚     â””â”€ Analytics.py                    # Analytics dashboard
â”‚
â”œâ”€ ğŸ“‚ tests/                             # Test suite
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ conftest.py                        # pytest fixtures
â”‚  â”œâ”€ ğŸ“‚ unit/                           # Unit tests
â”‚  â”‚  â”œâ”€ test_chunking.py
â”‚  â”‚  â”œâ”€ test_retrieval.py
â”‚  â”‚  â”œâ”€ test_generation.py
â”‚  â”‚  â””â”€ test_utils.py
â”‚  â””â”€ ğŸ“‚ integration/                    # Integration tests
â”‚     â”œâ”€ test_pipeline.py                # End-to-end pipeline
â”‚     â””â”€ test_api.py                     # API endpoint tests
â”‚
â”œâ”€ ğŸ“‚ .github/workflows/                 # CI/CD pipelines
â”‚  â”œâ”€ ci.yml                             # Continuous Integration
â”‚  â””â”€ cd.yml                             # Continuous Deployment
â”‚
â”œâ”€ ğŸ“‚ docker/                            # Docker configurations
â”‚  â”œâ”€ Dockerfile                         # Multi-stage Docker build
â”‚  â”œâ”€ docker-compose.yml                 # Local development stack
â”‚  â””â”€ .dockerignore
â”‚
â”œâ”€ ğŸ“‚ docs/                              # Documentation (MkDocs)
â”‚  â”œâ”€ index.md
â”‚  â”œâ”€ architecture.md                    # System architecture
â”‚  â”œâ”€ api_reference.md                   # API documentation
â”‚  â”œâ”€ deployment.md                      # Deployment guide
â”‚  â””â”€ development.md                     # Development guide
â”‚
â”œâ”€ ğŸ“‚ notebooks/                         # Jupyter notebooks
â”‚  â”œâ”€ ğŸ“‚ legacy/                         # Original academic work
â”‚  â”‚  â”œâ”€ MNA_NLP_actividad_chatbot_LLM_RAG (3).ipynb
â”‚  â”‚  â””â”€ NLP_LLM_con_RAG_y_VectorDatabase_FAISS_Chrome_Wikipedia.ipynb
â”‚  â””â”€ ğŸ“‚ experiments/                    # Experimental notebooks
â”‚     â”œâ”€ 01_data_exploration.ipynb
â”‚     â”œâ”€ 02_embedding_comparison.ipynb
â”‚     â”œâ”€ 03_prompt_tuning.ipynb
â”‚     â””â”€ 04_evaluation_analysis.ipynb
â”‚
â”œâ”€ ğŸ“‚ data/                              # Data directory
â”‚  â”œâ”€ ğŸ“‚ raw/                            # Raw PDF files (30+)
â”‚  â”œâ”€ ğŸ“‚ processed/                      # Processed chunks (JSON/parquet)
â”‚  â””â”€ ğŸ“‚ vector_stores/                  # Persisted vector indices
â”‚
â”œâ”€ ğŸ“‚ Books/                             # Reference materials (analysis source)
â”‚  â”œâ”€ ğŸ“‚ llm/                            # LLM engineering books
â”‚  â””â”€ ğŸ“‚ story-telling/                  # Storytelling & UX books
â”‚
â”œâ”€ ğŸ“‚ Complementarios Peru/              # Official Peru tourism PDFs
â”‚
â”œâ”€ .env.example                          # Environment variables template
â”œâ”€ .gitignore                            # Git ignore patterns
â”œâ”€ .pre-commit-config.yaml               # Pre-commit hooks
â”œâ”€ pyproject.toml                        # Project metadata & dependencies
â”œâ”€ requirements.txt                      # Python dependencies
â”œâ”€ requirements-dev.txt                  # Development dependencies
â”œâ”€ setup.py                              # Package setup
â”œâ”€ mkdocs.yml                            # MkDocs configuration
â”œâ”€ pytest.ini                            # pytest configuration
â”œâ”€ LICENSE                               # MIT License
â””â”€ README.md                             # This file
```

### **Directory Responsibilities**

| Directory | Purpose | Key Files | Owner Role |
|-----------|---------|-----------|------------|
| `src/data_pipeline/` | Data ingestion & processing | `pdf_loader.py`, `chunkers/` | **Data Engineer** |
| `src/embedding_pipeline/` | Embedding generation | `sentence_transformer.py` | **ML Engineer** |
| `src/vector_store/` | Vector database management | `faiss_store.py`, `chroma_store.py` | **Backend Engineer** |
| `src/retrieval_pipeline/` | Retrieval & reranking | `dense_retriever.py` | **ML Engineer** |
| `src/inference_pipeline/` | LLM inference & RAG chain | `rag_chain.py`, `mistral_client.py` | **ML Engineer** |
| `src/evaluation/` | Metrics & evaluation | `ragas_evaluator.py` | **ML Engineer / QA** |
| `api/` | REST API endpoints | `main.py`, `routers/` | **Backend Engineer** |
| `app/` | User interface | `Home.py`, `pages/` | **Frontend Engineer** |
| `tests/` | Test suite | `unit/`, `integration/` | **QA Engineer** |
| `.github/workflows/` | CI/CD pipelines | `ci.yml`, `cd.yml` | **DevOps Engineer** |
| `docker/` | Containerization | `Dockerfile`, `docker-compose.yml` | **DevOps Engineer** |
| `docs/` | Documentation | `*.md` files | **Technical Writer** |

---

## ğŸ› ï¸ Tech Stack

### **Core Technologies**

| Component | Technology | Version | Justification (From Research) |
|-----------|-----------|---------|-------------------------------|
| **Python** | Python | 3.10+ | Industry standard for ML/AI |
| **LLM** | Mistral-7B-Instruct | v0.3 | *LLM Handbook p.289*: "Open-source models offer production-grade performance" |
| **Embeddings** | sentence-transformers/<br>paraphrase-multilingual-mpnet | base-v2 | *Hands-On LLMs p.145*: "Multilingual transformers excel at cross-lingual search" |
| **Vector DB** | FAISS (dev)<br>Chroma (prod) | Latest | *LLM Handbook p.158*: "FAISS for prototyping, Chroma for production" |
| **Orchestration** | LangChain | 0.1+ | 30 mentions of pipeline orchestration in research |
| **API Framework** | FastAPI | 0.104+ | *LLM Handbook p.312*: "Async support crucial for LLM latency" |
| **UI Framework** | Streamlit | 1.28+ | Rapid prototyping for user testing |
| **Evaluation** | RAGAS | 0.1+ | *LLM Handbook p.272*: "RAGAS designed for RAG evaluation" |

### **Infrastructure & DevOps**

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Containerization** | Docker, Docker Compose | Environment reproducibility |
| **CI/CD** | GitHub Actions | Automated testing & deployment |
| **Logging** | structlog | Structured logging for observability |
| **Monitoring** | Prometheus + Grafana | Metrics collection & visualization |
| **Testing** | pytest, pytest-cov | Unit & integration testing |
| **Linting** | ruff, black, mypy | Code quality & type checking |
| **Documentation** | MkDocs | Auto-generated docs |

### **Development Tools**

```bash
# Core dependencies
langchain>=0.1.0
langchain-community>=0.0.20
sentence-transformers>=2.2.0
faiss-cpu>=1.7.4  # or faiss-gpu
chromadb>=0.4.0
fastapi>=0.104.0
uvicorn>=0.24.0
streamlit>=1.28.0
pydantic>=2.5.0
pydantic-settings>=2.1.0

# Evaluation
ragas>=0.1.0

# Utilities
python-dotenv>=1.0.0
structlog>=23.2.0
prometheus-client>=0.19.0

# Development
pytest>=7.4.0
pytest-cov>=4.1.0
pytest-asyncio>=0.21.0
black>=23.12.0
ruff>=0.1.9
mypy>=1.7.0
pre-commit>=3.6.0

# Documentation
mkdocs>=1.5.0
mkdocs-material>=9.5.0
```

---

## ğŸš€ Getting Started

### **Prerequisites**

- Python 3.10+
- Git
- Docker (optional, for containerized deployment)
- 8GB+ RAM (for local LLM inference)

### **Installation**

#### **Option 1: Local Development (Recommended for development)**

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/peruguide-rag.git
cd peruguide-rag

# 2. Activate Conda environment (already created)
conda activate peruguide-rag

# 3. Install dependencies in Conda environment
pip install -r requirements.txt
pip install -r requirements-dev.txt  # For development

# 4. Setup environment variables
cp .env.example .env
# Edit .env with your configurations (paths agnÃ³sticos)

# 5. Download & prepare data (agnÃ³stico - cualquier PDF)
# Configurar PDF_SOURCE_DIR en .env segÃºn tu fuente
python scripts/prepare_data.py

# 6. Build vector store
python scripts/build_vector_store.py

# 7. Run tests
pytest tests/ -v --cov=src --cov-report=html

# 8. Start API server
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000

# 9. Start UI (in another terminal)
streamlit run app/Home.py
```

#### **Option 2: Docker Compose (Recommended for production)**

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/peruguide-rag.git
cd peruguide-rag

# 2. Setup environment variables
cp .env.example .env
# Edit .env with your configurations

# 3. Build and run
docker-compose up --build

# Services will be available at:
# - API: http://localhost:8000
# - UI: http://localhost:8501
# - Docs: http://localhost:8000/docs
```

### **Quick Test**

```bash
# Test the API
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "Â¿QuÃ© visitar en Cusco?"}'

# Expected response:
{
  "answer": "En Cusco puedes visitar...",
  "sources": [
    {"document": "CUSCO_GPPV.pdf", "page": 23, "confidence": 0.89}
  ],
  "confidence": 0.89,
  "latency_ms": 1243
}
```

---

## ğŸ‘¥ Development Roles

This project follows a **multi-role professional structure** to ensure clean, maintainable, and production-ready code. Each role has specific responsibilities and deliverables.

### **Role 1: Data Engineer** ğŸ—„ï¸

**Responsibilities:**
- Design and implement data ingestion pipelines
- Ensure data quality and consistency
- Optimize data processing performance
- Maintain data documentation

**Key Deliverables:**
- âœ… `src/data_pipeline/loaders/pdf_loader.py` - PDF extraction
- âœ… `src/data_pipeline/processors/cleaner.py` - Text preprocessing
- âœ… `src/data_pipeline/chunkers/recursive_splitter.py` - Chunking strategy
- âœ… Data validation scripts
- âœ… Data quality metrics dashboard

**Testing Requirements:**
- Unit tests for each loader/processor
- Integration tests for full pipeline
- Performance benchmarks (throughput, latency)

---

### **Role 2: ML Engineer** ğŸ¤–

**Responsibilities:**
- Implement embedding generation pipeline
- Design and optimize RAG retrieval
- Fine-tune LLM inference parameters
- Evaluate model performance with RAGAS

**Key Deliverables:**
- âœ… `src/embedding_pipeline/models/sentence_transformer.py`
- âœ… `src/retrieval_pipeline/retrievers/dense_retriever.py`
- âœ… `src/inference_pipeline/chains/rag_chain.py`
- âœ… `src/evaluation/ragas_evaluator.py`
- âœ… Evaluation report (faithfulness, relevancy, precision)

**Testing Requirements:**
- Unit tests for embedding/retrieval/generation
- RAGAS evaluation (>0.85 faithfulness target)
- A/B tests for prompt variations
- Latency benchmarks (p50, p95, p99)

---

### **Role 3: Backend Engineer** âš™ï¸

**Responsibilities:**
- Design and implement REST API
- Manage vector store integration
- Ensure API security and rate limiting
- Optimize API performance

**Key Deliverables:**
- âœ… `api/main.py` - FastAPI application
- âœ… `api/routers/query.py` - Query endpoint
- âœ… `api/middleware/auth.py` - Authentication
- âœ… `api/middleware/rate_limit.py` - Rate limiting
- âœ… OpenAPI documentation

**Testing Requirements:**
- Unit tests for each endpoint
- Integration tests for API workflows
- Load testing (1000+ RPS capacity)
- Security audit (OWASP Top 10)

---

### **Role 4: Frontend Engineer** ğŸ¨

**Responsibilities:**
- Design and implement user interface
- Ensure responsive and accessible design
- Integrate with backend API
- Implement user feedback mechanisms

**Key Deliverables:**
- âœ… `app/Home.py` - Streamlit main app
- âœ… `app/pages/Chat.py` - Chat interface
- âœ… `app/pages/Sources.py` - Source browser
- âœ… `app/pages/Analytics.py` - Analytics dashboard
- âœ… UI/UX documentation

**Testing Requirements:**
- Manual UI/UX testing
- Cross-browser compatibility
- Accessibility audit (WCAG 2.1 AA)
- User acceptance testing (UAT)

---

### **Role 5: DevOps Engineer** ğŸ”§

**Responsibilities:**
- Setup CI/CD pipelines
- Containerize application with Docker
- Implement monitoring and observability
- Manage deployment and infrastructure

**Key Deliverables:**
- âœ… `.github/workflows/ci.yml` - CI pipeline
- âœ… `.github/workflows/cd.yml` - CD pipeline
- âœ… `docker/Dockerfile` - Multi-stage build
- âœ… `docker/docker-compose.yml` - Local stack
- âœ… Monitoring dashboards (Prometheus + Grafana)

**Testing Requirements:**
- CI pipeline validates all tests pass
- Docker image security scan
- Deployment smoke tests
- Monitoring alerts configured

---

### **Role 6: QA Engineer** âœ…

**Responsibilities:**
- Write comprehensive test suite
- Ensure code coverage >75%
- Perform integration and E2E testing
- Document test cases and results

**Key Deliverables:**
- âœ… `tests/unit/` - Unit test suite
- âœ… `tests/integration/` - Integration tests
- âœ… `tests/conftest.py` - pytest fixtures
- âœ… Test coverage report (HTML)
- âœ… QA documentation

**Testing Requirements:**
- >75% code coverage
- All critical paths tested
- Regression test suite
- Performance test suite

---

### **Role 7: Technical Writer** ğŸ“

**Responsibilities:**
- Write comprehensive documentation
- Maintain API reference docs
- Create deployment guides
- Document architecture decisions

**Key Deliverables:**
- âœ… `docs/index.md` - Documentation home
- âœ… `docs/architecture.md` - System architecture
- âœ… `docs/api_reference.md` - API docs
- âœ… `docs/deployment.md` - Deployment guide
- âœ… `README.md` - Project README

**Testing Requirements:**
- All docs reviewed for accuracy
- Code examples tested
- Links validated
- Documentation versioning

---

## ğŸ“Š Evaluation & Metrics

### **RAGAS Evaluation Framework**

Following **LLM Engineer's Handbook (Chapter 7, p.272-283)**, we use RAGAS for RAG-specific evaluation:

| Metric | Definition | Target | Current |
|--------|-----------|--------|---------|
| **Faithfulness** | Are responses grounded in retrieved context? | >0.85 | TBD |
| **Answer Relevancy** | Does the answer address the question? | >0.80 | TBD |
| **Context Precision** | Are retrieved chunks relevant? | >0.75 | TBD |
| **Context Recall** | Was all necessary info retrieved? | >0.70 | TBD |
| **Latency (p95)** | Response time 95th percentile | <3 sec | TBD |

### **Test Dataset**

Located in `src/evaluation/test_dataset.json`:
- 100+ curated Q&A pairs
- Ground truth answers from PDFs
- Multiple question categories:
  - Temporal (best time to visit)
  - Location (what to see)
  - Logistics (how to get there)
  - Budget (cost estimates)

### **Running Evaluation**

```bash
# Run RAGAS evaluation
python -m src.evaluation.ragas_evaluator \
  --test-dataset src/evaluation/test_dataset.json \
  --output results/evaluation_report.json

# View results
python scripts/visualize_metrics.py results/evaluation_report.json
```

---

## ğŸ“š Documentation

### **Documentation Structure**

Documentation is built with **MkDocs** and hosted on GitHub Pages:

```
docs/
â”œâ”€ index.md                 # Documentation home
â”œâ”€ getting-started.md       # Installation & setup
â”œâ”€ architecture.md          # System architecture deep dive
â”œâ”€ api-reference.md         # API endpoint documentation
â”œâ”€ development.md           # Development guidelines
â”œâ”€ deployment.md            # Deployment guide (Docker, cloud)
â”œâ”€ evaluation.md            # Evaluation methodology
â”œâ”€ troubleshooting.md       # Common issues & solutions
â””â”€ contributing.md          # Contribution guidelines
```

### **Building Documentation Locally**

```bash
# Install MkDocs
pip install mkdocs mkdocs-material

# Serve locally
mkdocs serve

# Build static site
mkdocs build

# Deploy to GitHub Pages
mkdocs gh-deploy
```

### **API Documentation**

FastAPI auto-generates interactive API documentation:

- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc
- **OpenAPI JSON:** http://localhost:8000/openapi.json

---

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](docs/contributing.md) for details.

### **Development Workflow**

```bash
# 1. Fork the repository
# 2. Create a feature branch
git checkout -b feature/your-feature-name

# 3. Make changes and commit
git add .
git commit -m "feat: add your feature"

# 4. Run tests
pytest tests/ -v --cov=src

# 5. Run linters
ruff check src/ tests/
black src/ tests/
mypy src/

# 6. Push and create PR
git push origin feature/your-feature-name
```

### **Commit Convention**

We follow [Conventional Commits](https://www.conventionalcommits.org/):

- `feat:` New feature
- `fix:` Bug fix
- `docs:` Documentation changes
- `test:` Test additions/changes
- `refactor:` Code refactoring
- `chore:` Maintenance tasks

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

This project is built on the shoulders of giants. Special thanks to:

### **Research & Books Analyzed (2,959 pages)**

1. **LLM Engineer's Handbook** - Paul Iusztin & Maxime Labonne (523 pages)
2. **Build a Large Language Model (From Scratch)** - Sebastian Raschka (281 pages)
3. **Hands-On Large Language Models** - Jay Alammar & Maarten Grootendorst (598 pages)
4. **Designing Large Language Model Applications** (88 pages)
5. **Storytelling with Data** - Cole Nussbaumer Knaflic (284 pages)
6. **Effective Data Storytelling** - Brent Dykes (413 pages)
7. **User Story Mapping** - Jeff Patton (397 pages)
8. **Practical Natural Language Processing** (455 pages)
9. **Large Language Models Meet NLP: A Survey** (20 pages)

### **Open Source Libraries**

- [LangChain](https://langchain.com) - LLM orchestration framework
- [Mistral AI](https://mistral.ai) - Open-source LLM
- [FAISS](https://github.com/facebookresearch/faiss) - Vector similarity search
- [ChromaDB](https://www.trychroma.com) - Vector database
- [FastAPI](https://fastapi.tiangolo.com) - Modern API framework
- [Streamlit](https://streamlit.io) - Data app framework

### **Data Source**

- **PROMPERÃš** - Official Peru tourism guides (30+ PDFs, 5,000+ pages)

---

## ğŸ“ Contact

- **Author:** [Your Name]
- **Email:** your.email@example.com
- **LinkedIn:** [linkedin.com/in/yourprofile](https://linkedin.com/in/yourprofile)
- **GitHub:** [@yourusername](https://github.com/yourusername)
- **Portfolio:** [yourportfolio.com](https://yourportfolio.com)

---

## ğŸ¯ Project Status

**Current Phase:** Level 2 - Production-Ready Implementation

### **Roadmap**

- [x] **Phase 0:** Research & Analysis (2,959 pages analyzed)
- [x] **Phase 1:** Project Planning & Architecture Design
- [ ] **Phase 2:** Feature Pipeline Implementation (Week 1)
- [ ] **Phase 3:** Inference Pipeline Implementation (Week 2)
- [ ] **Phase 4:** Evaluation & API Development (Week 3)
- [ ] **Phase 5:** Deployment & Documentation (Week 4)
- [ ] **Phase 6:** Level 3 Enhancements (Optional)

### **Metrics Dashboard**

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Code Coverage | >75% | 0% | ğŸ”´ Not started |
| RAGAS Faithfulness | >0.85 | - | ğŸ”´ Not started |
| API Latency (p95) | <3s | - | ğŸ”´ Not started |
| Documentation | 100% | 30% | ğŸŸ¡ In progress |
| Test Suite | 100+ tests | 0 | ğŸ”´ Not started |

---

<div align="center">

**â­ If this project helps you, please star it! â­**

Made with â¤ï¸ and lots of â˜• in Peru ğŸ‡µğŸ‡ª

</div>
